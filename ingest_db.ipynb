{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0eda32c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, inspect\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05a872b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///inventory.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d641ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(206529, 9)\n",
      "(224489, 9)\n",
      "(2372474, 16)\n",
      "(12261, 9)\n",
      "(12825363, 14)\n",
      "(5543, 10)\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('data'):\n",
    "    if '.csv' in file:\n",
    "        df= pd.read_csv('data/' + file)\n",
    "        print(df.shape)\n",
    "        ingest_db(df, file[:,-4], engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "110cdf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing begin_inventory.csv...\n",
      "  - Ingested chunk 2 for begin_inventory\n",
      "  - Ingested chunk 3 for begin_inventory\n",
      "✅ Finished ingesting 'begin_inventory' in 2.95 seconds.\n",
      "\n",
      "Processing end_inventory.csv...\n",
      "  - Ingested chunk 2 for end_inventory\n",
      "  - Ingested chunk 3 for end_inventory\n",
      "✅ Finished ingesting 'end_inventory' in 2.91 seconds.\n",
      "\n",
      "Processing purchases.csv...\n",
      "  - Ingested chunk 2 for purchases\n",
      "  - Ingested chunk 3 for purchases\n",
      "  - Ingested chunk 4 for purchases\n",
      "  - Ingested chunk 5 for purchases\n",
      "  - Ingested chunk 6 for purchases\n",
      "  - Ingested chunk 7 for purchases\n",
      "  - Ingested chunk 8 for purchases\n",
      "  - Ingested chunk 9 for purchases\n",
      "  - Ingested chunk 10 for purchases\n",
      "  - Ingested chunk 11 for purchases\n",
      "  - Ingested chunk 12 for purchases\n",
      "  - Ingested chunk 13 for purchases\n",
      "  - Ingested chunk 14 for purchases\n",
      "  - Ingested chunk 15 for purchases\n",
      "  - Ingested chunk 16 for purchases\n",
      "  - Ingested chunk 17 for purchases\n",
      "  - Ingested chunk 18 for purchases\n",
      "  - Ingested chunk 19 for purchases\n",
      "  - Ingested chunk 20 for purchases\n",
      "  - Ingested chunk 21 for purchases\n",
      "  - Ingested chunk 22 for purchases\n",
      "  - Ingested chunk 23 for purchases\n",
      "  - Ingested chunk 24 for purchases\n",
      "✅ Finished ingesting 'purchases' in 42.18 seconds.\n",
      "\n",
      "Processing purchase_prices.csv...\n",
      "✅ Finished ingesting 'purchase_prices' in 0.37 seconds.\n",
      "\n",
      "Processing sales.csv...\n",
      "  - Ingested chunk 2 for sales\n",
      "  - Ingested chunk 3 for sales\n",
      "  - Ingested chunk 4 for sales\n",
      "  - Ingested chunk 5 for sales\n",
      "  - Ingested chunk 6 for sales\n",
      "  - Ingested chunk 7 for sales\n",
      "  - Ingested chunk 8 for sales\n",
      "  - Ingested chunk 9 for sales\n",
      "  - Ingested chunk 10 for sales\n",
      "  - Ingested chunk 11 for sales\n",
      "  - Ingested chunk 12 for sales\n",
      "  - Ingested chunk 13 for sales\n",
      "  - Ingested chunk 14 for sales\n",
      "  - Ingested chunk 15 for sales\n",
      "  - Ingested chunk 16 for sales\n",
      "  - Ingested chunk 17 for sales\n",
      "  - Ingested chunk 18 for sales\n",
      "  - Ingested chunk 19 for sales\n",
      "  - Ingested chunk 20 for sales\n",
      "  - Ingested chunk 21 for sales\n",
      "  - Ingested chunk 22 for sales\n",
      "  - Ingested chunk 23 for sales\n",
      "  - Ingested chunk 24 for sales\n",
      "  - Ingested chunk 25 for sales\n",
      "  - Ingested chunk 26 for sales\n",
      "  - Ingested chunk 27 for sales\n",
      "  - Ingested chunk 28 for sales\n",
      "  - Ingested chunk 29 for sales\n",
      "  - Ingested chunk 30 for sales\n",
      "  - Ingested chunk 31 for sales\n",
      "  - Ingested chunk 32 for sales\n",
      "  - Ingested chunk 33 for sales\n",
      "  - Ingested chunk 34 for sales\n",
      "  - Ingested chunk 35 for sales\n",
      "  - Ingested chunk 36 for sales\n",
      "  - Ingested chunk 37 for sales\n",
      "  - Ingested chunk 38 for sales\n",
      "  - Ingested chunk 39 for sales\n",
      "  - Ingested chunk 40 for sales\n",
      "  - Ingested chunk 41 for sales\n",
      "  - Ingested chunk 42 for sales\n",
      "  - Ingested chunk 43 for sales\n",
      "  - Ingested chunk 44 for sales\n",
      "  - Ingested chunk 45 for sales\n",
      "  - Ingested chunk 46 for sales\n",
      "  - Ingested chunk 47 for sales\n",
      "  - Ingested chunk 48 for sales\n",
      "  - Ingested chunk 49 for sales\n",
      "  - Ingested chunk 50 for sales\n",
      "  - Ingested chunk 51 for sales\n",
      "  - Ingested chunk 52 for sales\n",
      "  - Ingested chunk 53 for sales\n",
      "  - Ingested chunk 54 for sales\n",
      "  - Ingested chunk 55 for sales\n",
      "  - Ingested chunk 56 for sales\n",
      "  - Ingested chunk 57 for sales\n",
      "  - Ingested chunk 58 for sales\n",
      "  - Ingested chunk 59 for sales\n",
      "  - Ingested chunk 60 for sales\n",
      "  - Ingested chunk 61 for sales\n",
      "  - Ingested chunk 62 for sales\n",
      "  - Ingested chunk 63 for sales\n",
      "  - Ingested chunk 64 for sales\n",
      "  - Ingested chunk 65 for sales\n",
      "  - Ingested chunk 66 for sales\n",
      "  - Ingested chunk 67 for sales\n",
      "  - Ingested chunk 68 for sales\n",
      "  - Ingested chunk 69 for sales\n",
      "  - Ingested chunk 70 for sales\n",
      "  - Ingested chunk 71 for sales\n",
      "  - Ingested chunk 72 for sales\n",
      "  - Ingested chunk 73 for sales\n",
      "  - Ingested chunk 74 for sales\n",
      "  - Ingested chunk 75 for sales\n",
      "  - Ingested chunk 76 for sales\n",
      "  - Ingested chunk 77 for sales\n",
      "  - Ingested chunk 78 for sales\n",
      "  - Ingested chunk 79 for sales\n",
      "  - Ingested chunk 80 for sales\n",
      "  - Ingested chunk 81 for sales\n",
      "  - Ingested chunk 82 for sales\n",
      "  - Ingested chunk 83 for sales\n",
      "  - Ingested chunk 84 for sales\n",
      "  - Ingested chunk 85 for sales\n",
      "  - Ingested chunk 86 for sales\n",
      "  - Ingested chunk 87 for sales\n",
      "  - Ingested chunk 88 for sales\n",
      "  - Ingested chunk 89 for sales\n",
      "  - Ingested chunk 90 for sales\n",
      "  - Ingested chunk 91 for sales\n",
      "  - Ingested chunk 92 for sales\n",
      "  - Ingested chunk 93 for sales\n",
      "  - Ingested chunk 94 for sales\n",
      "  - Ingested chunk 95 for sales\n",
      "  - Ingested chunk 96 for sales\n",
      "  - Ingested chunk 97 for sales\n",
      "  - Ingested chunk 98 for sales\n",
      "  - Ingested chunk 99 for sales\n",
      "  - Ingested chunk 100 for sales\n",
      "  - Ingested chunk 101 for sales\n",
      "  - Ingested chunk 102 for sales\n",
      "  - Ingested chunk 103 for sales\n",
      "  - Ingested chunk 104 for sales\n",
      "  - Ingested chunk 105 for sales\n",
      "  - Ingested chunk 106 for sales\n",
      "  - Ingested chunk 107 for sales\n",
      "  - Ingested chunk 108 for sales\n",
      "  - Ingested chunk 109 for sales\n",
      "  - Ingested chunk 110 for sales\n",
      "  - Ingested chunk 111 for sales\n",
      "  - Ingested chunk 112 for sales\n",
      "  - Ingested chunk 113 for sales\n",
      "  - Ingested chunk 114 for sales\n",
      "  - Ingested chunk 115 for sales\n",
      "  - Ingested chunk 116 for sales\n",
      "  - Ingested chunk 117 for sales\n",
      "  - Ingested chunk 118 for sales\n",
      "  - Ingested chunk 119 for sales\n",
      "  - Ingested chunk 120 for sales\n",
      "  - Ingested chunk 121 for sales\n",
      "  - Ingested chunk 122 for sales\n",
      "  - Ingested chunk 123 for sales\n",
      "  - Ingested chunk 124 for sales\n",
      "  - Ingested chunk 125 for sales\n",
      "  - Ingested chunk 126 for sales\n",
      "  - Ingested chunk 127 for sales\n",
      "  - Ingested chunk 128 for sales\n",
      "  - Ingested chunk 129 for sales\n",
      "✅ Finished ingesting 'sales' in 210.61 seconds.\n",
      "\n",
      "Processing vendor_invoice.csv...\n",
      "✅ Finished ingesting 'vendor_invoice' in 0.30 seconds.\n",
      "\n",
      "All files have been successfully ingested into the database.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import time\n",
    "\n",
    "def ingest_data_in_chunks(file_path, table_name, engine, chunk_size=100000):\n",
    "    \"\"\"\n",
    "    Reads a large CSV file in chunks and ingests it into a SQL database.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): The full path to the CSV file.\n",
    "        table_name (str): The name of the SQL table to create.\n",
    "        engine: The SQLAlchemy engine connection.\n",
    "        chunk_size (int): The number of rows per chunk.\n",
    "    \"\"\"\n",
    "    print(f\"Processing {os.path.basename(file_path)}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create an iterator object that reads the CSV in chunks\n",
    "    df_iterator = pd.read_csv(file_path, chunksize=chunk_size, low_memory=False)\n",
    "    \n",
    "    # Get the first chunk to create the table structure\n",
    "    first_chunk = next(df_iterator)\n",
    "    \n",
    "    # Write the first chunk to the database, replacing any existing table\n",
    "    first_chunk.to_sql(table_name, con=engine, if_exists='replace', index=False)\n",
    "    \n",
    "    # Now, loop through the remaining chunks and append them\n",
    "    for i, chunk in enumerate(df_iterator, 1):\n",
    "        chunk.to_sql(table_name, con=engine, if_exists='append', index=False)\n",
    "        print(f\"  - Ingested chunk {i+1} for {table_name}\")\n",
    "        \n",
    "    end_time = time.time()\n",
    "    print(f\"✅ Finished ingesting '{table_name}' in {end_time - start_time:.2f} seconds.\\n\")\n",
    "\n",
    "\n",
    "# --- Main Script ---\n",
    "# Create a connection engine to the SQLite database\n",
    "engine = create_engine('sqlite:///inventory.db')\n",
    "data_directory = 'data'\n",
    "\n",
    "for file_name in os.listdir(data_directory):\n",
    "    if file_name.endswith('.csv'):\n",
    "        # Construct the full file path\n",
    "        full_path = os.path.join(data_directory, file_name)\n",
    "        \n",
    "        # Create a clean table name by removing the '.csv' extension\n",
    "        table_name = file_name[:-4] \n",
    "        \n",
    "        # Call the ingestion function\n",
    "        ingest_data_in_chunks(file_path=full_path, table_name=table_name, engine=engine)\n",
    "\n",
    "print(\"All files have been successfully ingested into the database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1cc7ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting database: inventory.db\n",
      "========================================\n",
      "Table: begin_inventory      | Rows: 206529     | Columns: 9\n",
      "Table: end_inventory        | Rows: 224489     | Columns: 9\n",
      "Table: purchase_prices      | Rows: 12261      | Columns: 9\n",
      "Table: purchases            | Rows: 2372474    | Columns: 16\n",
      "Table: sales                | Rows: 12825363   | Columns: 14\n",
      "Table: vendor_invoice       | Rows: 5543       | Columns: 10\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Configuration ---\n",
    "db_path = 'sqlite:///inventory.db'\n",
    "\n",
    "# --- Script ---\n",
    "engine = create_engine(db_path)\n",
    "inspector = inspect(engine)\n",
    "\n",
    "# Get the list of all table names in the database\n",
    "table_names = inspector.get_table_names()\n",
    "\n",
    "print(f\"Inspecting database: {db_path.split('/')[-1]}\\n\" + \"=\"*40)\n",
    "\n",
    "# Loop through each table to get its dimensions\n",
    "for table in table_names:\n",
    "    # Query to count rows (very memory-efficient)\n",
    "    row_count_query = f\"SELECT COUNT(*) FROM {table}\"\n",
    "    row_count = pd.read_sql_query(row_count_query, engine).iloc[0, 0]\n",
    "    \n",
    "    # Query to count columns using SQLite's PRAGMA (also memory-efficient)\n",
    "    col_count_query = f\"PRAGMA table_info({table});\"\n",
    "    col_count = len(pd.read_sql_query(col_count_query, engine))\n",
    "    \n",
    "    # Print the results in a formatted way\n",
    "    print(f\"Table: {table:<20} | Rows: {row_count:<10} | Columns: {col_count}\")\n",
    "\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa2e756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
